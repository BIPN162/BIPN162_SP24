{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c53287",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "\n",
    "* Use `scikit learn` to run a linear regression both to explore the relationship between two variables *and* for prediction.\n",
    "* Implement **bootstrapping** in Python.\n",
    "* Interpret the outputs of models in Python using your conceptual understanding of regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355346f8",
   "metadata": {},
   "source": [
    "## Part I: Regression for data exploration & description\n",
    "\n",
    "First, we'll look at a data that contains information about the size of various species' brains and the number of neurons that they have! This data is from [Suzana Herculano-Houzel, a Brazilian neuroscientist](https://suzanaherculanohouzel.com/about/).\n",
    "\n",
    "<img src=\"https://www.frontiersin.org/files/Articles/857/fnhum-03-031/image_n/fnhum-03-031-g004.gif\" alt=\"image\" width=\"400\"/>\n",
    "\n",
    "[Image source](https://www.frontiersin.org/articles/10.3389/neuro.09.031.2009/full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc5a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('Data/species_brainmass_neurons.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a88eb85",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\"><b>Task</b>: Inspect the Pearson correlation and visual relationship between the mass of the cortex and the number of neurons.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a706e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pearsons correlation\n",
    "\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedb8e0",
   "metadata": {},
   "source": [
    "Below, we'll use [`LinearRegression`](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html) from `sklearn` to fit our model and add both the predicted # of neurons *and* the residuals to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b463f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1 - Initialize the kind of model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 2 - Fit the model\n",
    "model.fit(df[['cortex_mass_g']],df['Neurons'])\n",
    "\n",
    "# 3 - Predict the values of \"Neurons\" based on \"cortex_mass_g\"\n",
    "df['Neurons Prediction'] = model.predict(df[['cortex_mass_g']])\n",
    "\n",
    "# 4 - Calculate the residuals\n",
    "df['Residuals'] = df['Neurons'] - df['Neurons Prediction']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81361c",
   "metadata": {},
   "source": [
    "Let's take a look at the predicted values and some important outputs from the modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322a967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"Coefficients: \\n\", model.coef_)\n",
    "print(\"Intercept: \\n\", model.intercept_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(df['Neurons'], df['Neurons Prediction']))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(df['Neurons'], df['Neurons Prediction']))\n",
    "\n",
    "plt.scatter(df['cortex_mass_g'],df['Neurons Prediction'])\n",
    "plt.xlabel('cortex mass (g)')\n",
    "plt.ylabel('predicted # neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6753b6",
   "metadata": {},
   "source": [
    "Hmm, this doesn't seem like a great predictor in the entire dataset!\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Task</b>: Run the same analysis above, fitting a linear model, but do so with *only* the primates in the data (<code>df['Order']=='Primata'</code>). Is the relationship between # of neurons and cortex size in the primate data better described by a linear fit?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64792be",
   "metadata": {},
   "source": [
    "### Bootstrapping to assess uncertainty\n",
    "\n",
    "We can choose random samples from our data as well. \n",
    "\n",
    "<div class=\"alert alert-success\"><b>Task</b>: Finish the function below (replace the <code>...</code> to implement bootstrapping.\n",
    "\n",
    "Hint: <code><a href=\"https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\">np.random.choice</a></code> will definitely be useful here! Note the \"replace\" argument. Then, plot the randomly sampled data.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040c410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resample_with_replacement(x, y):\n",
    "    \"\"\"Resample data points with replacement from the dataset of `x` inputs and `y` measurements.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): An array of shape (samples,) that contains the input values.\n",
    "        y (ndarray): An array of shape (samples,) that contains the corresponding\n",
    "      measurement values to the inputs.\n",
    "\n",
    "    Returns:\n",
    "        ndarray, ndarray: The newly resampled `x` and `y` data points.\n",
    "  \"\"\"\n",
    "\n",
    "    # Get array of indices for resampled points\n",
    "    sample_idx = ...\n",
    "\n",
    "    # Sample from x and y according to sample_idx\n",
    "    x_ = ...\n",
    "    y_ = ...\n",
    "\n",
    "    return x_, y_\n",
    "\n",
    "x_, y_ = resample_with_replacement(df['cortex_mass_g'],df['Neurons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94632398",
   "metadata": {},
   "source": [
    "(Note that some of the data may be plotted over other data, because we are allowing resampling!) \n",
    "\n",
    "Now, we can implement a method to run the bootstrap process of generating a set of values from a dataset of inputs (x) and measurements (y).\n",
    "\n",
    "We'll use the `resample_with_replacement` function here, and we'll also choose estimates by minimizing the **mean square error** using least squares optimization in this line of code: `estimates[i] = (x_.T @ y_) / (x_.T @ x_)`. **Note**: We will not fully explore the derivation of this equation in this course; if you're curious, see [this tutorial](https://compneuro.neuromatch.io/tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1.html#section-2-least-squares-optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b90c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_estimates(x, y, n=2000):\n",
    "    \"\"\"Generate a set of theta_hat estimates using the bootstrap method.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): An array of shape (samples,) that contains the input values.\n",
    "        y (ndarray): An array of shape (samples,) that contains the corresponding\n",
    "      measurement values to the inputs.\n",
    "        n (int): The number of estimates to compute\n",
    "\n",
    "    Returns:\n",
    "        ndarray: An array of estimated parameters with size (n,)\n",
    "  \"\"\"\n",
    "\n",
    "    estimates = np.zeros(n)\n",
    "\n",
    "    # Loop over number of estimates\n",
    "    for i in range(n):\n",
    "\n",
    "        # Resample x and y\n",
    "        x_, y_ = resample_with_replacement(x, y)\n",
    "\n",
    "        # Compute theta_hat (estimated parameters) for this sample\n",
    "        estimates[i] = (x_.T @ y_) / (x_.T @ x_)\n",
    "\n",
    "    return estimates\n",
    "\n",
    "# Set random seed (optional)\n",
    "#np.random.seed(123)\n",
    "\n",
    "# Get bootstrap estimates\n",
    "estimates = bootstrap_estimates( df['cortex_mass_g'], df['Neurons'],n=2000)\n",
    "print(estimates[0:5])\n",
    "print(f\"mean = {np.mean(estimates):.2f}, std = {np.std(estimates):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a6989",
   "metadata": {},
   "source": [
    "Now that we have our bootstrap estimates, we can visualize all the potential models (models computed with different resampling) together to see how distributed they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3176b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['cortex_mass_g']\n",
    "y = df['Neurons']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# For each estimate, plot model\n",
    "\n",
    "for i, estimate in enumerate(estimates):\n",
    "    y_hat = estimate * x\n",
    "    ax.plot(x, y_hat, c='r', alpha=0.01, label='Resampled Fits' if i==0 else '')\n",
    "\n",
    "# Plot observed data\n",
    "ax.scatter(x, y, label='Observed')\n",
    "\n",
    "# Plot true fit data\n",
    "y_true = model.intercept_ + model.coef_ * x\n",
    "ax.plot(x, y_true, 'g', linewidth=2, label='True Model')\n",
    "\n",
    "ax.set(title='Bootstrapped Slope Estimation', xlabel='x', ylabel='y')\n",
    "\n",
    "# Change legend line alpha property\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles[0].set_alpha(1)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aee3d7",
   "metadata": {},
   "source": [
    "Finally, we can quantify how uncertain our estimated slope is. We do so by computing [confidence intervals (CIs)](https://en.wikipedia.org/wiki/Confidence_interval) from our bootstrapped estimates. The most direct approach is to compute percentiles from the empirical distribution of bootstrapped estimates. Note that this approach is widely applicable -- it does not assume this distribution is Gaussian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464462a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(estimates, bins=20, facecolor='C1', alpha=0.75)\n",
    "ax.axvline(model.coef_, c='g', label=r'True $\\theta$')\n",
    "ax.axvline(np.percentile(estimates, 50), color='r', label='Median')\n",
    "ax.axvline(np.percentile(estimates, 2.5), color='b', label='95% CI')\n",
    "ax.axvline(np.percentile(estimates, 97.5), color='b')\n",
    "ax.legend()\n",
    "ax.set(title='Bootstrapped Confidence Interval',xlabel=r'$\\hat{{\\theta}}$',ylabel='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fcf93",
   "metadata": {},
   "source": [
    "## Part II: Regression for prediction\n",
    "\n",
    "We can also use regression for prediction. Below, we'll use a dataset of **2-photon calcium imaging** to measure neural activity in mice while they're running on a wheel and viewing visual stimuli. We don't have access to the animal's performance on the task, but we can still use the animal's movement on the wheel (a very rich measure of arousal, actually!) as an interesting behavioral output.\n",
    "\n",
    "First, let's get some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adc5c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allen specific toolboxes\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "boc = BrainObservatoryCache(manifest_file='Data/manifest.json')\n",
    "\n",
    "exps = boc.get_ophys_experiments(cre_lines=['Sst-IRES-Cre'], stimuli=['drifting_gratings'])\n",
    "\n",
    "pd.DataFrame(exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a180470",
   "metadata": {},
   "source": [
    "Now that we have our list of experiments in the Sst-IRES-Cre line, we can get the raw data for one of them. This will take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c191819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's just look at the first session\n",
    "session_id = exps[0]['id']\n",
    "data_set = boc.get_ophys_experiment_data(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828d71a",
   "metadata": {},
   "source": [
    "Then, we can plot a mean of all of the fluorescence traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1ad9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get all of the fluorescence traces (ts = timestamps; dff = deltaF/F)\n",
    "ts, dff = data_set.get_dff_traces()\n",
    "\n",
    "# Get the average change in fluorescence\n",
    "dff_mean = dff.mean(axis=0)\n",
    "\n",
    "# Plot the sum of all of the fluorescence activity\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(ts,dff_mean)\n",
    "plt.xlabel('Seconds (s)')\n",
    "plt.ylabel('$\\Delta$F/F')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d020968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the running speed from this dataset (dxcm = distance in cm; ts = timestamps)\n",
    "dxcm, ts = data_set.get_running_speed()\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(ts,dxcm)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Speed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd6fc2",
   "metadata": {},
   "source": [
    "Running activity is fairly coarse, so rather than try to predict the activity at 30Hz, let's bin the activity (summed across all neurons) into bins of 5 seconds. We also need to get rid of ~NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91215208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bin_size = 5\n",
    "bin_stamps = np.arange(0,ts.max(),bin_size)\n",
    "num_bins = len(bin_stamps)\n",
    "\n",
    "run_bin = np.empty(num_bins)\n",
    "response_bin = np.empty(num_bins)\n",
    "\n",
    "for i in range(num_bins):\n",
    "    \n",
    "    # Get the values within our time bin and take a mean\n",
    "    run_bin[i] = dxcm[np.where((ts>i*bin_size)&(ts<((i+1)*bin_size)))].mean() \n",
    "    response_bin[i] = dff_mean[np.where((ts>i*bin_size)&(ts<((i+1)*bin_size)))].mean()\n",
    "\n",
    "response_bin = response_bin[~np.isnan(run_bin)]\n",
    "run_bin = run_bin[~np.isnan(run_bin)]\n",
    "\n",
    "# Scale the response trace so we can see it alongside running\n",
    "response_bin_scaled = response_bin*40\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(run_bin,label='Running')\n",
    "plt.plot(response_bin_scaled,label='Response')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4c2f6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><b>Task</b>: Now that you have <code>response_bin</code> and <code>run_bin</code> we can ask a prediction question: does the animal's movement predict neural activity?\n",
    "    \n",
    "To answer this question, we'll devise a test set of the first 200 samples and see if we can use the coefficient predicted by a linear model to predict the remaining samples.\n",
    "    \n",
    "1. Run a linear regression on the first 200 samples. Obtain the coefficient from this linear regression.\n",
    "2. Multiply the remaining samples by the coefficient to obtain a list of predicted values.\n",
    "3. Plot these predicted values along side the actual response values.\n",
    "4. Assess this prediction using both a Pearson's r and R^2 statistic.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we predict neural activity from behavior?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a072a27",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "Some of the material here was adapted from [Neuromatch Academy](https://compneuro.neuromatch.io/tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3.html). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
