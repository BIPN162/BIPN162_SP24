{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b98a52-e92b-4ff5-a2bf-692c3496cef2",
   "metadata": {},
   "source": [
    "# Matrix Factorization \n",
    "### Application to an auditory fMRI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7935ed-a07c-4835-bb14-b436ec25f7ee",
   "metadata": {},
   "source": [
    "### Tutorial Objectives\n",
    "\n",
    "In this tutorial, we'll apply non-negative matrix factorization to an auditory fMRI data where participants listened to 165 natural sounds.\n",
    "Here, we will:\n",
    "\n",
    "1.\tLoad the preprocessed fMRI data and understand the data attributes and perform some basic visualizations <br>\n",
    "2.\tApply and compare two different versions of the non-negative matrix factorization algorithm <br>\n",
    "3.  Plot how the reconstruction error varies as a a function of the number of components <br>\n",
    "4.  Interpret the response profiles of the resulting components to search for music and speech-selective neural populations <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c197166-ecd9-4baf-a1d0-abfad58ffa07",
   "metadata": {},
   "source": [
    "<b>Motivation: </b>When we measure voxel response with fMRI, we measure an aggregated activity across hundreds of thousands of neurons. Presumably, there are a relatively small number of types of neural populations in these voxels. Each of these neural population will have a distinctive response profile over the sound set.\n",
    "And voxels have different proportions of the different neural population types.\n",
    "But what we measure in an fMRI experiment is the voxelâ€™s response to sounds and our goal is to recover the response profiles of different neural populations and their anatomical proportions within every voxel (i.e. to demix the voxel responses).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058ba31-7dcd-4346-9c5e-3706a52ed300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the required libraries -- should not be necessary!\n",
    "# !pip install playsound\n",
    "# !pip install nimfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44cd28-c187-4406-a966-1ded5bb0ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import nimfa \n",
    "from playsound import playsound\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import glob, os, requests\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0722b5d-d3d0-48ed-8ae0-d9741fe9c15e",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d7450-eb6d-49ae-93b7-2a1209ace66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Data retrieval\n",
    "\n",
    "fname = \"data.zip\"\n",
    "url = \"https://osf.io/uhkez/download\"\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "  try:\n",
    "    r = requests.get(url)\n",
    "  except requests.ConnectionError:\n",
    "    print(\"!!! Failed to download data !!!\")\n",
    "  else:\n",
    "    if r.status_code != requests.codes.ok:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      with open(fname, \"wb\") as fid:\n",
    "        fid.write(r.content)\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edead15f-22d9-481c-ab60-a19026954a28",
   "metadata": {},
   "source": [
    "### Load data and understand the data attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8b41c-6386-4ce3-abe7-167d0eb3a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "data = sio.loadmat('data/data_matrix.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797be736-fa2a-4e15-95dc-94c7dacc4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data attributes \n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30513528-73c4-48a2-910a-44ea74211ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filepaths of all stimuli\n",
    "wav_dir = 'data/stimuli/wav'\n",
    "\n",
    "stim_names = np.concatenate(data['stim_names'][0],0) \n",
    "stim_paths = np.array([\"%s/%s.wav\" % (wav_dir, name) for name in stim_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c63723-16cc-4c72-8713-a2e709b12932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the category labels of all sounds\n",
    "labels = pd.read_csv('data/stimuli/category_labels.csv', index_col = 'stimulus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e845d5-524e-4f52-a1d3-a7c393e31ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the labels based on stimulus names \n",
    "categories = labels.loc[stim_names, 'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca17ebf-8b34-4a2e-b392-11d04468950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play sample sounds from the dataset\n",
    "idx = 0\n",
    "stim_path, category = stim_paths[idx], categories[idx]\n",
    "print('Playing sound from the %s category' % category)\n",
    "playsound(stim_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab36941-2872-4ce3-8a46-cf23e178b99f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> <b>*** Tasks *** </b><br>\n",
    "    <b>(a). Average the fMRI responses across repetitions to create the data matrix  </b><br>\n",
    "    <b>(b). Visualize the response of an example voxel to all sounds  </b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337570d2-20cb-4457-bd96-ff33228fd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991039b3-62c3-493f-98ad-0690dbc4e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d51fa9-234f-4d13-9b2a-589d4b12f7fb",
   "metadata": {},
   "source": [
    "### Apply two versions of NMF on the data <br>\n",
    "(a) Standard NMF using `nimfa.Nmf` <br>\n",
    "(b) Sparse NMF using `nimfa.Snmf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ae67b-28bc-40e7-9b00-856f6d56b2cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> <b>*** Tasks *** </b><br>\n",
    "    <b>As seen from the visualization above, voxel responses can sometimes be negative. To apply NMF (or its variants) on the data, we need non-negative data. \n",
    "To make the data matrix suitable for NMF so that it contains all positive entries, we can perform a baseline shift of voxel responses by subtracting the minimum response of each voxel (across all stimuli) from its responses to all stimuli. \n",
    "    In the following cell, perform this operation and store the result in a variable `nn_data`</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec684f-6170-4e54-80e3-16aac634166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the non-negative entries in the data \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7168905-d72a-491c-ab7d-2f64b7449cce",
   "metadata": {},
   "source": [
    "##### Here, we will apply both the NMF methods on your non-negative data and compute the reconstruction error in each case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5f14e-9b1a-4b6e-a019-48591f2fc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "standard_nmf = nimfa.Nmf(nn_data, seed=\"nndsvd\", rank=n_components, max_iter=12, update='euclidean', objective='fro')\n",
    "standard_nmf_fit = standard_nmf()\n",
    "\n",
    "print('Standard NMF RSS: %5.4f' % standard_nmf_fit.fit.rss())\n",
    "\n",
    "snmf = nimfa.Snmf(nn_data, seed=\"nndsvd\", rank=n_components, max_iter=12, version='r',\n",
    "                  eta=1., beta=1e-4, i_conv=10, w_min_change=0)\n",
    "snmf_fit = snmf()\n",
    "print('Sparse NMF RSS: %5.4f' % snmf_fit.fit.rss())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22647917-2dd8-474a-9665-ce54f21ef368",
   "metadata": {},
   "source": [
    "_Q. Which one is better?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313bbec-4d3c-42df-bf56-ef083ff1dd97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> <b>*** Tasks *** </b><br>\n",
    "    <b>Use the better NMF approach and plot the reconstruction error (residual sum of squares) as a function of the number of components, varying the component number from 1 through 10  </b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99caacf-7a52-457e-9f36-41eb79ad6131",
   "metadata": {},
   "source": [
    "### Selecting the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a2c8e-180e-4ea2-aea2-839706435e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss = []\n",
    "n_range = range(1,11)\n",
    "for n_components in n_range:\n",
    "    nmf = ...(nn_data, seed=\"nndsvd\", rank=n_components, max_iter=12, version='r',\n",
    "                      eta=1., beta=1e-4, i_conv=10, w_min_change=0)\n",
    "    nmf_fit = nmf()\n",
    "    rss.append(nmf_fit.fit.rss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b616e3-248c-4862-bcf2-299a1d266052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reconstruction error as a function of the number of components\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f3edc-12b7-4aa0-b05f-6b02d9de59e4",
   "metadata": {},
   "source": [
    "_Q. What can you conclude from this plot?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0e024-7073-4855-9f1f-95269aa993ba",
   "metadata": {},
   "source": [
    "### Applying NMF with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b6779-2ff0-4b31-978c-71960926376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 6\n",
    "snmf = nimfa.Snmf(nn_data, seed=\"nndsvd\", rank=n_components, max_iter=12, version='l',\n",
    "                      eta=1., beta=1e-4, i_conv=10, w_min_change=0)\n",
    "snmf_fit = snmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280588b-24ec-4464-8097-9016a480e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the response profile matrix and the component weight matrix \n",
    "response_profile = np.asarray(snmf_fit.basis().T)\n",
    "voxel_weight = np.asarray(snmf_fit.coef())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39494fea-4c96-4003-b638-34c09ad6090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the extracted low-dimensional matrices \n",
    "voxel_weight.shape, response_profile.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659eb7a2-ed8a-4d63-a682-640d7b7880e0",
   "metadata": {},
   "source": [
    "### Interpreting the response profiles of components "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd563ef8-ad3f-47d6-bf76-f7972467c696",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> <b>*** Tasks *** </b><br>\n",
    "    <b>a. Visualize the response profile of all components using the function below and try to infer if there are indeed music and speech-selective neural populations  </b><br>\n",
    "    <b>b. Play the top 10 sounds for the music and speech-selective components </b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4033f352-92f1-4506-b3c6-6a0527643fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_component_response(idx = 0):\n",
    "    \n",
    "    sorted_categories = categories[np.argsort(response_profile[idx])][::-1]\n",
    "    sorted_response = np.sort(response_profile[idx])[::-1]\n",
    "    \n",
    "    sns.set(font_scale=1, style = 'white') \n",
    "    \n",
    "    colors = ['khaki', 'darkkhaki', 'indianred', 'orchid', 'brown', 'blue', 'slateblue', 'peru', 'seagreen', 'lightgray', 'mediumseagreen']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (7,3))\n",
    "    for loc, cat_name in enumerate(np.unique(sorted_categories)): \n",
    "        markers, stems, base = plt.stem(np.where(sorted_categories == cat_name)[0], sorted_response[sorted_categories==cat_name], colors[loc], basefmt=\" \", label=cat_name, markerfmt=\" \")\n",
    "        plt.setp(stems, 'linewidth', 1.4)\n",
    "        \n",
    "    plt.legend(ncol = 3, fontsize = 10)\n",
    "    plt.xlabel('Sound number (sorted by response)', fontweight = 'bold', fontsize = 12);\n",
    "    plt.ylabel('Component response', fontweight = 'bold', fontsize = 12)\n",
    "    plt.title('Response profile of component # %d' % idx, fontweight = 'bold', fontsize = 12); \n",
    "\n",
    "visualize_component_response(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e986f-5a17-47f4-989d-bea0fb4cdcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play top 10 sounds of the music and speech-speech selective components \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bb8b2-f1f1-4920-ae07-b667663ae4b7",
   "metadata": {},
   "source": [
    "#### Acknowledgements \n",
    "This dataset of fMRI responses to auditory sounds was collected by Sam Norman-Haignere and released as part of the following publication: \n",
    "Norman-Haignere, Sam, Nancy G. Kanwisher, and Josh H. McDermott. \"Distinct cortical pathways for music and speech revealed by hypothesis-free voxel decomposition.\" Neuron \n",
    "                                                                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
