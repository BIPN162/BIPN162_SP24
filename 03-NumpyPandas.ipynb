{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NumPy & Pandas\n",
    "In this notebook, we'll encounter two packages for scientific computing in Python: NumPy and Pandas.\n",
    "\n",
    "**At the end of this notebook, you'll be able to:**\n",
    "* Install and import packages for Python\n",
    "* Create NumPy arrays\n",
    "* Execute methods & access attributes of arrays\n",
    "* Create & manipulate Pandas dataframes\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing packages\n",
    "\n",
    "Before we can use NumPy or Pandas, we need to import them. We can also nickname the modules when we import them.\n",
    "\n",
    "The convention is to import `numpy` as `np` and `pandas` as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use whos 'magic command' to see available modules\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NumPy\n",
    "\n",
    "**NumPy** is the fundamental package for scientific computing with Python. It'll allow us to work with bigger datasets more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating `numpy` arrays\n",
    "\n",
    "A numpy **array** is a grid of values which are all the same [data type](https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html).\n",
    "\n",
    "We can create a numpy array in a few different ways:\n",
    "\n",
    "* from a Python list or tuples\n",
    "* by using functions that are dedicated to generating numpy arrays, such as `arange`, `linspace`, `empty`,`zeroes`, etc.\n",
    "* reading data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list\n",
    "lst = [1,2,3,4,5]\n",
    "\n",
    "# Make our list into an array\n",
    "my_matrix = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# If we give np.array() a list of lists, it will create a matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accessing attributes of numpy arrays\n",
    "We can test shape and size either by looking at the attribute of the array, or by using the `shape()` and `size()` functions.\n",
    "\n",
    "Other attributes that might be of interest are `ndim` and `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Check the dimensions of vector\n",
    "\n",
    "# Check the dimensions of matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Array data type is decided upon creation of the array.\n",
    "\n",
    "You can explicitly define the data type by using `dtype= ` when you use `np.array()`. You can set the dtype to be `int, float, complex, bool, object`, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use dtype here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Indexing & slicing arrays\n",
    "\n",
    "Indexing and slicing 1D arrays (vectors) is similar to indexing lists.\n",
    "\n",
    "You can index NumPy arrays using `array_name[row,column]` to select a single value. If you omit the column, it will give you the entire row. You can also use `:` in place of either `row` or `column` to indicate you want to return all those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task**: Create an array of booleans called `bool_array` that is 2 rows x 3 columns. Access the `shape` and `ndim` attributes to confirm its size, and the `dtype` attribute to confirm that it is boolean.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_matrix[[0,2],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to look at a slice of columns or a slice of rows. You can slice your array like the following: `array(start_row:stop_row, start_col:end_col)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 3 columns of each row \n",
    "my_matrix[: ,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Subsetting arrays\n",
    "We can also subset our original array to only include data that meets our criteria. We can think of this as **subsetting** the array by applying a condition to our array. The syntax for this would be new_array = original_array[condition]. This is essentially indexing/slicing the array using a Boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([lst, lst])\n",
    "\n",
    "# Return only values greater than 3 from our array \n",
    "condition = (my_array > 3)\n",
    "filtered_array = my_array[condition]\n",
    "print(filtered_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task**: Subset `bool_array` so that it is only the true values.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also change values in an array similar to how we would change values in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Assign a value to an index in my_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Benefits of using arrays\n",
    "In addition to being less clunky & a bit faster than lists of lists, arrays can do a lot of things that lists can't. For example, we can add and multiply them. Alternatively, we can use the `sum` method to sum across a specific axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate differences between lists and arrays\n",
    "sum_list = [1,3,5] + [3,5,7]\n",
    "sum_array = np.array([1,3,5]) + np.array([3,5,7])\n",
    "mult_array = np.array([1,3,5]) * np.array([3,5,7])\n",
    "\n",
    "print(sum_list)\n",
    "print(mult_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Sum over a specific axis\n",
    "this_array = np.array([[1,3,5],[3,5,7]])\n",
    "sum_rows = this_array.sum(axis=1)\n",
    "print(this_array)\n",
    "print(sum_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numpy also includes some very useful array generating functions:\n",
    "\n",
    "* `arange`: like `range` but gives you a useful numpy array, instead of an interator, and can use more than just integers)\n",
    "* `linspace` creates an array with given start and end points, and a desired number of points\n",
    "* `logspace` same as linspace, but in log.\n",
    "* `random` can create a random list (there are <a href=\"https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html\">many different ways to use this</a>)\n",
    "* `concatenate` which can concatenate two arrays along an existing axis [<a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html\">documentation</a>]\n",
    "* `hstack` and `vstack` which can horizontally or vertically stack arrays\n",
    "\n",
    "Whenever we call these, we need to use whatever name we imported numpy as (here, `np`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# When using linspace, both end points are included!\n",
    "np.linspace(0,147,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Numpy also has built in methods to save and load arrays: `np.save()` and `np.load()`. Numpy files have a .npy extension.\n",
    "\n",
    "See full documentation <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save method takes arguments 'filename' and then 'array':\n",
    "np.save('matrix',my_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_new_matrix = np.load('matrix.npy')\n",
    "my_new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is a useful module that creates **dataframes** (think of these like Excel spreadsheets, but much faster!). We can think of Pandas as \"numpy with labels\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Benefits of Pandas\n",
    "* Great for real-world, heterogeneous data\n",
    "* Similar to Excel spreadsheets (but way faster!)\n",
    "* Smartly deals with missing data\n",
    "\n",
    "The two data structures of Pandas are the `Series` and the `DataFrame`. A `Series` is a one-dimensional onject similar to a list. A `DataFrame` can be thought of as a two-dimensional numpy array or a collection of `Series` objects. Series and dataframes can contain multiple different data types such as integers, strings, and floats, similar to an Excel spreadsheet. Pandas also supports `string` lables unlike numpy arrays which only have numeric labels for their rows and columns. For a more in depth explanation, please visit the [Introduction to Data Structures](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html) section in the Pandas User Guide. \n",
    "\n",
    "You can create a Pandas dataframe by inputting dictionaries into the Pandas function `pd.DataFrame()`, by reading files, or through functions built into the Pandas package. The function [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) reads a comma- or tab-separated file and returns it as a `dataframe`.\n",
    "\n",
    "\n",
    "## Loading in data as a dataframe\n",
    "Below we will create a dataframe by reading the file `brainarea_vs_genes_exp_w_reannotations.tsv` which contains information on gene expression accross multiple brain areas. \n",
    "\n",
    ">**About this dataset:**\n",
    "This dataset was created by Derek Howard and Abigail Mayes for the purpose of accelerating advances in data mining of open brain transcriptome data for polygenetic brain disorders. The data comes from normalized microarray datasets of gene expression from 6 adult human brains that was released by the Allen Brain Institute and then processed into the dataframe we will see below. For more information on this dataset please visit the <a href = \"https://github.com/derekhoward/HBAsets\"> HBAsets repository</a>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the file as a data frame\n",
    "file_name = 'Data/brainarea_vs_genes_exp_w_reannotations.tsv'\n",
    "\n",
    "# Use pd.read_csv\n",
    "gene_df = ...\n",
    "\n",
    "# '.head()' returns the first 5 rows in the dataframe\n",
    "gene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, the first column  of information above, the **index** just contains a list of numbers. We can reassign the row labels by using the method `set_index()`. We can choose any column in our present dataframe to be the row values. Let's assign the row lables to be the `gene_symbol` and reassign the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index\n",
    "gene_df = gene_df.set_index('gene_symbol')\n",
    "gene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing\n",
    "\n",
    "Indexing in Pandas works slightly different than in NumPy. Similar to a dictionary, we can index dataframes by their names. \n",
    "\n",
    "The syntax for indexing single locations in a dataframe is `dataframe.loc[row_label,column_label]`. To index an individual column, we use the shorthand syntax `dataframe[column_label]`. To index an individual row, we use the syntax `dataframe.loc[row_label]`. To index by index #, we use the syntax `dataframe.iloc[index_number]`. Below are some examples on how to access rows, columns, and single values in our dataframe. For more information on indexing dataframes, visit the <a href = \"https://pandas.pydata.org/docs/user_guide/indexing.html#indexing\"> \"Indexing and selecting data\"</a> section in the Pandas User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get 'DISC1' data using loc\n",
    "DISC1_data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas has many, many useful methods that you can use on your data, including `describe`, `mean`, and more. To learn more about all the different methods that can be used to manipulate and analyze dataframes, please visit the <a href = \"https://pandas.pydata.org/docs/user_guide/index.html\"> Pandas User Guide </a>. \n",
    "* The `describe` method returns descriptive statistics of all the columns in our dataframe. \n",
    "* The `mean` and `std` method return the mean and standard deviation of each column in the dataframe, respectfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Try out mean & std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Challenge Task**: Reading Malformed `.csv` Files\n",
    "    \n",
    "</div>\n",
    "\n",
    "`Data/malformed.csv` is a file of comma-separated values, containing the following fields:\n",
    "\n",
    "|column name|description|type|\n",
    "|---|---|---|\n",
    "|`'first'`|first name of person|`str`|\n",
    "|`'last'`|last name of person|`str`|\n",
    "|`'weight'`|weight of person (lbs)|`float`|\n",
    "|`'height'`|height of person (in)|`float`|\n",
    "|`'geo'`|location of person; comma-separated latitude/longitude|`str`|\n",
    "\n",
    "Unfortunately, the entries contains errors with the placement of commas (`,`) and quotes (`\\\"`) that cause `pandas`' `read_csv` function to fail parsing the file with the default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('Data/malformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, instead of using `pd.read_csv`, you must read in the file manually using Python's built-in `open` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the open function\n",
    "The built-in function [`open`](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) takes in a file path and returns a file object (sometimes called a file handle), which we can then iterate over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('Data/malformed.csv') as fh:\n",
    "    for line in fh:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, complete the implementation of the function `parse_malformed`, which takes in a file path (`fp`) and returns a parsed, properly-typed DataFrame with the information in the corresponding file. For example, `fp` may be `'Data/malformed.csv'`. The DataFrame should contain the columns described in the data description table above (with the specified types).\n",
    "\n",
    "**Note:**\n",
    "* The only kinds of issues you need your function to handle are comma and quote misplacements; don't try and find any other issues with the CSV.\n",
    "* With that said, you should assume that `Data/malformed.csv` is a sample of a larger file that has the same sorts of errors, but potentially in different lines. For example, `Data/malformed.csv` has an unnecessary quote `\\\"` in line 4, but your function may be called on another CSV that has a perfectly fine line 4 but an unnecessary quote on some other line.\n",
    "* So, **don't** implement `parse_malformed` assuming that the commas and quotes are mispositioned on specific lines; rather, implement `parse_malformed` such that it can handle these issues on every single line they appear in.\n",
    "* A good way to proceed is to open `Data/malformed.csv` and look carefully at the comma and quote placements.\n",
    "* You may want to use `fields = line.strip().split(',')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_malformed(fp):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "Check out the <a href=\"https://docs.scipy.org/doc/numpy/user/index.html\">NumPy user guide</a> if you ever have a question about a NumPy array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "This notebook is largely derived from UCSD COGS18 Materials, created by Tom Donoghue & Shannon Ellis, <a href=\"https://github.com/jrjohansson/scientific-python-lectures/blob/master/Lecture-2-Numpy.ipynb\">JR Johannson's Scientific Python Lecture on Numpy</a>, and DSC80 materials \n",
    "\n",
    "\n",
    "Want to run this notebook as a slideshow? If you have Python (or Anaconda) follow <a href=\"http://www.blog.pythonlibrary.org/2018/09/25/creating-presentations-with-jupyter-notebook/\">these instructions</a> to setup your computer with the RISE plugin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": {
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
